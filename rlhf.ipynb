{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "919e2916-5d69-4534-b2bb-60ac472890fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Downloading vllm-0.7.2-cp38-abi3-manylinux1_x86_64.whl (264.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.3/264.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: pyyaml in /venv/main/lib/python3.10/site-packages (from vllm) (6.0.2)\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 KB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision==0.20.1 in /venv/main/lib/python3.10/site-packages (from vllm) (0.20.1+cu121)\n",
      "Collecting depyf==0.18.0\n",
      "  Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting numpy<2.0.0\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: pyzmq in /venv/main/lib/python3.10/site-packages (from vllm) (26.2.1)\n",
      "Collecting compressed-tensors==0.9.1\n",
      "  Downloading compressed_tensors-0.9.1-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 KB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting ray[default]>=2.9\n",
      "  Downloading ray-2.42.1-cp310-cp310-manylinux2014_x86_64.whl (67.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting tokenizers>=0.19.1\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting pydantic>=2.9\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 KB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting uvicorn[standard]\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Collecting msgspec\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 KB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting mistral_common[opencv]>=1.5.0\n",
      "  Downloading mistral_common-1.5.3-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting nvidia-ml-py>=12.560.30\n",
      "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting tiktoken>=0.6.0\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock>=3.16.1 in /venv/main/lib/python3.10/site-packages (from vllm) (3.17.0)\n",
      "Collecting openai>=1.52.0\n",
      "  Downloading openai-1.63.0-py3-none-any.whl (472 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.3/472.3 KB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting lark==1.2.2\n",
      "  Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 KB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting gguf==0.10.0\n",
      "  Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 KB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting prometheus-fastapi-instrumentator>=7.0.0\n",
      "  Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.10/site-packages (from vllm) (4.67.1)\n",
      "Collecting transformers>=4.48.2\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.9\n",
      "  Downloading lm_format_enforcer-0.10.9-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting outlines==0.1.11\n",
      "  Downloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 KB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /venv/main/lib/python3.10/site-packages (from vllm) (6.1.1)\n",
      "Collecting xgrammar>=0.1.6\n",
      "  Downloading xgrammar-0.1.11-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (396 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.2/396.2 KB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting importlib_metadata\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: torchaudio==2.5.1 in /venv/main/lib/python3.10/site-packages (from vllm) (2.5.1+cu121)\n",
      "Requirement already satisfied: pillow in /venv/main/lib/python3.10/site-packages (from vllm) (11.0.0)\n",
      "Collecting blake3\n",
      "  Downloading blake3-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.4/376.4 KB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting fastapi!=0.113.*,!=0.114.0,>=0.107.0\n",
      "  Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 KB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch==2.5.1 in /venv/main/lib/python3.10/site-packages (from vllm) (2.5.1+cu121)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.11.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /venv/main/lib/python3.10/site-packages (from vllm) (2.32.3)\n",
      "Collecting partial-json-parser\n",
      "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
      "Collecting xformers==0.0.28.post3\n",
      "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=4.10 in /venv/main/lib/python3.10/site-packages (from vllm) (4.12.2)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 KB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting prometheus_client>=0.18.0\n",
      "  Downloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 KB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 KB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (3.1.4)\n",
      "Collecting referencing\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Collecting pycountry\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting airportsdata\n",
      "  Downloading airportsdata-20241001-py3-none-any.whl (912 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 KB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting outlines_core==0.1.26\n",
      "  Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 KB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting jsonschema\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 KB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting interegular\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Collecting diskcache\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 KB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nest_asyncio in /venv/main/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (3.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.1.0.106)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (1.13.1)\n",
      "Requirement already satisfied: triton==3.1.0 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch==2.5.1->vllm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /venv/main/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: packaging in /venv/main/lib/python3.10/site-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (24.2)\n",
      "Collecting opencv-python-headless>=4.0.0\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 KB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 KB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 KB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting click>=7.0\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 KB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 KB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 KB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting opencensus\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 KB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting smart-open\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 KB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24\n",
      "  Downloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting grpcio>=1.42.0\n",
      "  Downloading grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting colorful\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 KB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 KB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 KB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 KB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests>=2.26.0->vllm) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests>=2.26.0->vllm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests>=2.26.0->vllm) (2.3.0)\n",
      "Collecting regex>=2022.1.18\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /venv/main/lib/python3.10/site-packages (from tokenizers>=0.19.1->vllm) (0.28.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 KB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting pybind11\n",
      "  Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 KB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting pytest\n",
      "  Using cached pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "Collecting zipp>=3.20\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting httptools>=0.6.3\n",
      "  Using cached httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-14.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.3/169.3 KB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Using cached uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Collecting python-dotenv>=0.13\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /venv/main/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.52.0->vllm) (1.2.2)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.22.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.0/382.0 KB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /venv/main/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (4.3.6)\n",
      "Collecting distlib<1,>=0.3.7\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->outlines==0.1.11->vllm) (2.1.5)\n",
      "Collecting opencensus-context>=0.1.3\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Requirement already satisfied: six~=1.16 in /venv/main/lib/python3.10/site-packages (from opencensus->ray[default]>=2.9->vllm) (1.17.0)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 KB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting iniconfig\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting tomli>=1\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Collecting pluggy<2,>=1.5\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 KB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.67.0-py2.py3-none-any.whl (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 KB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 KB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 KB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: sentencepiece, py-spy, py-cpuinfo, opencensus-context, nvidia-ml-py, distlib, colorful, blake3, zipp, wrapt, websockets, virtualenv, uvloop, tomli, sniffio, safetensors, rpds-py, regex, python-dotenv, pydantic-core, pycountry, pybind11, pyasn1, protobuf, propcache, prometheus_client, pluggy, partial-json-parser, numpy, multidict, msgspec, msgpack, lark, jiter, interegular, iniconfig, httptools, h11, grpcio, frozenlist, einops, distro, diskcache, dill, cloudpickle, click, cachetools, attrs, async-timeout, astor, annotated-types, airportsdata, aiohappyeyeballs, yarl, uvicorn, tiktoken, smart-open, rsa, referencing, pytest, pydantic, pyasn1-modules, proto-plus, opencv-python-headless, importlib_metadata, httpcore, googleapis-common-protos, gguf, depyf, anyio, aiosignal, watchfiles, tokenizers, starlette, lm-format-enforcer, jsonschema-specifications, httpx, google-auth, aiohttp, xformers, transformers, prometheus-fastapi-instrumentator, openai, jsonschema, google-api-core, fastapi, aiohttp-cors, xgrammar, ray, outlines_core, opencensus, mistral_common, compressed-tensors, outlines, vllm\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiohttp-cors-0.7.0 aiosignal-1.3.2 airportsdata-20241001 annotated-types-0.7.0 anyio-4.8.0 astor-0.8.1 async-timeout-5.0.1 attrs-25.1.0 blake3-1.0.4 cachetools-5.5.1 click-8.1.8 cloudpickle-3.1.1 colorful-0.5.6 compressed-tensors-0.9.1 depyf-0.18.0 dill-0.3.9 diskcache-5.6.3 distlib-0.3.9 distro-1.9.0 einops-0.8.1 fastapi-0.115.8 frozenlist-1.5.0 gguf-0.10.0 google-api-core-2.24.1 google-auth-2.38.0 googleapis-common-protos-1.67.0 grpcio-1.70.0 h11-0.14.0 httpcore-1.0.7 httptools-0.6.4 httpx-0.28.1 importlib_metadata-8.6.1 iniconfig-2.0.0 interegular-0.3.3 jiter-0.8.2 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 lark-1.2.2 lm-format-enforcer-0.10.9 mistral_common-1.5.3 msgpack-1.1.0 msgspec-0.19.0 multidict-6.1.0 numpy-1.26.4 nvidia-ml-py-12.570.86 openai-1.63.0 opencensus-0.11.4 opencensus-context-0.1.3 opencv-python-headless-4.11.0.86 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 pluggy-1.5.0 prometheus-fastapi-instrumentator-7.0.2 prometheus_client-0.21.1 propcache-0.2.1 proto-plus-1.26.0 protobuf-5.29.3 py-cpuinfo-9.0.0 py-spy-0.4.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pybind11-2.13.6 pycountry-24.6.1 pydantic-2.10.6 pydantic-core-2.27.2 pytest-8.3.4 python-dotenv-1.0.1 ray-2.42.1 referencing-0.36.2 regex-2024.11.6 rpds-py-0.22.3 rsa-4.9 safetensors-0.5.2 sentencepiece-0.2.0 smart-open-7.1.0 sniffio-1.3.1 starlette-0.45.3 tiktoken-0.9.0 tokenizers-0.21.0 tomli-2.2.1 transformers-4.48.3 uvicorn-0.34.0 uvloop-0.21.0 virtualenv-20.29.2 vllm-0.7.2 watchfiles-1.0.4 websockets-14.2 wrapt-1.17.2 xformers-0.0.28.post3 xgrammar-0.1.11 yarl-1.18.3 zipp-3.21.0\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: torch<3,>=2.0 in /venv/main/lib/python3.10/site-packages (from bitsandbytes) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/main/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: triton==3.1.0 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /venv/main/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.5)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.2\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-ap3uv3yd\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ap3uv3yd\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 336dc69d63d56f232a183a3e7f52790429b871ef\n",
      "  Installing build dependencies ... \u001b[done\n",
      "donetting requirements to build wheel ... \u001b[?25l\n",
      "doneeparing metadata (pyproject.toml) ... \u001b[?25l\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /venv/main/lib/python3.10/site-packages (from transformers==4.49.0.dev0) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/main/lib/python3.10/site-packages (from transformers==4.49.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.10/site-packages (from transformers==4.49.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.10/site-packages (from transformers==4.49.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /venv/main/lib/python3.10/site-packages (from transformers==4.49.0.dev0) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /venv/main/lib/python3.10/site-packages (from transformers==4.49.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from transformers==4.49.0.dev0) (3.17.0)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from transformers==4.49.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.10/site-packages (from transformers==4.49.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from transformers==4.49.0.dev0) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /venv/main/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/main/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49.0.dev0) (2025.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests->transformers==4.49.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->transformers==4.49.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests->transformers==4.49.0.dev0) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->transformers==4.49.0.dev0) (3.4.1)\n",
      "Building wheels for collected packages: transformers\n",
      "done.. \u001b[?25l\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.49.0.dev0-py3-none-any.whl size=10758753 sha256=e64035943bdbaa87d7b3ea215c1cf9e013e6816a41dbaf602c85b639241decf9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-he7abnnu/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.48.3\n",
      "    Uninstalling transformers-4.48.3:\n",
      "      Successfully uninstalled transformers-4.48.3\n",
      "Successfully installed transformers-4.49.0.dev0\n",
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-2pu7z_em\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-2pu7z_em\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 94be64dd195f30770a81b5c41ed99c9b68376026\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "donePreparing metadata (pyproject.toml) ... \u001b[?25l\n",
      "Requirement already satisfied: safetensors in /venv/main/lib/python3.10/site-packages (from peft==0.14.1.dev0) (0.5.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /venv/main/lib/python3.10/site-packages (from peft==0.14.1.dev0) (2.5.1+cu121)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.10/site-packages (from peft==0.14.1.dev0) (6.1.1)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.10/site-packages (from peft==0.14.1.dev0) (4.67.1)\n",
      "Collecting accelerate>=0.21.0\n",
      "  Downloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /venv/main/lib/python3.10/site-packages (from peft==0.14.1.dev0) (4.49.0.dev0)\n",
      "Requirement already satisfied: pyyaml in /venv/main/lib/python3.10/site-packages (from peft==0.14.1.dev0) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /venv/main/lib/python3.10/site-packages (from peft==0.14.1.dev0) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from peft==0.14.1.dev0) (24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/main/lib/python3.10/site-packages (from peft==0.14.1.dev0) (1.26.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/main/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2025.2.0)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /venv/main/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (4.12.2)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.17.0)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (3.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: triton==3.1.0 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /venv/main/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /venv/main/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.14.1.dev0) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.10/site-packages (from transformers->peft==0.14.1.dev0) (0.21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.10/site-packages (from transformers->peft==0.14.1.dev0) (2024.11.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.14.1.dev0) (2.1.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.10)\n",
      "Building wheels for collected packages: peft\n",
      "done wheel for peft (pyproject.toml) ... \u001b[?25l\n",
      "\u001b[?25h  Created wheel for peft: filename=peft-0.14.1.dev0-py3-none-any.whl size=395654 sha256=b675a1f9f4e8d070721aec9d5bcb2b5f6f9256dbe3cbd750b07679f11c9d14a3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rnnipyhx/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
      "Successfully built peft\n",
      "Installing collected packages: accelerate, peft\n",
      "Successfully installed accelerate-1.3.0 peft-0.14.1.dev0\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-uoay3u95\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-uoay3u95\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit 526925b48c07d997cdd9bf5911f659ca45778915\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "doneGetting requirements to build wheel ... \u001b[?25l\n",
      "donePreparing metadata (pyproject.toml) ... \u001b[?25l\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /venv/main/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (0.28.1)\n",
      "Requirement already satisfied: pyyaml in /venv/main/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (24.2)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (6.1.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (0.5.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /venv/main/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: torch>=2.0.0 in /venv/main/lib/python3.10/site-packages (from accelerate==1.4.0.dev0) (2.5.1+cu121)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/main/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (2025.2.0)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (3.17.0)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /venv/main/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /venv/main/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (1.13.1)\n",
      "Requirement already satisfied: triton==3.1.0 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /venv/main/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate==1.4.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.4.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate==1.4.0.dev0) (2.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.4.0.dev0) (2.3.0)\n",
      "Building wheels for collected packages: accelerate\n",
      "done wheel for accelerate (pyproject.toml) ... \u001b[?25l\n",
      "\u001b[?25h  Created wheel for accelerate: filename=accelerate-1.4.0.dev0-py3-none-any.whl size=339831 sha256=3e8656dd143ae384b51f06c8c956c14f2c1f8fee2ab4dc5a71c79e1e838a69c3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1deg_y73/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n",
      "Successfully built accelerate\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.3.0\n",
      "    Uninstalling accelerate-1.3.0:\n",
      "      Successfully uninstalled accelerate-1.3.0\n",
      "Successfully installed accelerate-1.4.0.dev0\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: ipywidgets in /venv/main/lib/python3.10/site-packages (8.1.5)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /venv/main/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-19.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: aiohttp in /venv/main/lib/python3.10/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: packaging in /venv/main/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/main/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Collecting fsspec[http]<=2024.9.0,>=2023.1.0\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 KB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.23.0 in /venv/main/lib/python3.10/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /venv/main/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 KB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from datasets) (3.17.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 KB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: comm>=0.1.3 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /venv/main/lib/python3.10/site-packages (from ipywidgets) (8.32.0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Requirement already satisfied: pillow>=8 in /venv/main/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /venv/main/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 KB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 KB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /venv/main/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: decorator in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: exceptiongroup in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: matplotlib-inline in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: stack_data in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /venv/main/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 KB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 KB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /venv/main/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /venv/main/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /venv/main/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: pure-eval in /venv/main/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in /venv/main/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /venv/main/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Installing collected packages: pytz, xxhash, tzdata, scipy, pyparsing, pyarrow, kiwisolver, fsspec, fonttools, dill, cycler, contourpy, pandas, multiprocess, matplotlib, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.2.0\n",
      "    Uninstalling fsspec-2025.2.0:\n",
      "      Successfully uninstalled fsspec-2025.2.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 datasets-3.2.0 dill-0.3.8 fonttools-4.56.0 fsspec-2024.9.0 kiwisolver-1.4.8 matplotlib-3.10.0 multiprocess-0.70.16 pandas-2.2.3 pyarrow-19.0.0 pyparsing-3.2.1 pytz-2025.1 scipy-1.15.1 tzdata-2025.1 xxhash-3.5.0\n",
      "Collecting trl\n",
      "  Downloading trl-0.15.0-py3-none-any.whl (318 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.3/318.3 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting rich\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 KB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.34.0 in /venv/main/lib/python3.10/site-packages (from trl) (1.4.0.dev0)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /venv/main/lib/python3.10/site-packages (from trl) (4.49.0.dev0)\n",
      "Requirement already satisfied: datasets>=2.21.0 in /venv/main/lib/python3.10/site-packages (from trl) (3.2.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /venv/main/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (0.28.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /venv/main/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (2.5.1+cu121)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (24.2)\n",
      "Requirement already satisfied: pyyaml in /venv/main/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (6.1.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (0.5.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /venv/main/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /venv/main/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /venv/main/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (3.5.0)\n",
      "Requirement already satisfied: pandas in /venv/main/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /venv/main/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (4.67.1)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /venv/main/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /venv/main/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (3.11.12)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (3.17.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /venv/main/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /venv/main/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (19.0.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /venv/main/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (0.70.16)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.10/site-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.10/site-packages (from transformers>=4.46.0->trl) (0.21.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /venv/main/lib/python3.10/site-packages (from rich->trl) (2.19.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /venv/main/lib/python3.10/site-packages (from rich->trl) (4.12.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (1.18.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (0.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (2.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (25.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (5.0.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /venv/main/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate>=0.34.0->trl) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/main/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/main/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.5)\n",
      "Installing collected packages: mdurl, markdown-it-py, rich, trl\n",
      "Successfully installed markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.9.4 trl-0.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install vllm\n",
    "# You only need to run this once per machine\n",
    "!pip install -U bitsandbytes\n",
    "!pip install -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -U datasets scipy ipywidgets matplotlib\n",
    "!pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa87261e-2cbe-48cf-8f78-f53b831ef158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /venv/main/lib/python3.10/site-packages (from tensorboard) (5.29.3)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /venv/main/lib/python3.10/site-packages (from tensorboard) (1.70.0)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 KB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /venv/main/lib/python3.10/site-packages (from tensorboard) (59.6.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /venv/main/lib/python3.10/site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: six>1.9 in /venv/main/lib/python3.10/site-packages (from tensorboard) (1.17.0)\n",
      "Requirement already satisfied: packaging in /venv/main/lib/python3.10/site-packages (from tensorboard) (24.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /venv/main/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, markdown, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 markdown-3.7 tensorboard-2.19.0 tensorboard-data-server-0.7.2 werkzeug-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b361e042-22d4-4507-a953-2ca87071774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import DPOTrainer, DPOConfig\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "073c2a02-a74a-4ef7-8bea-307e727fe5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950c6348357e44d5b450287eaf556fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "token = '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'\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_id, \n",
    "                                                  quantization_config=bnb_config, \n",
    "                                                  device_map=\"auto\", \n",
    "                                                  trust_remote_code=True, \n",
    "                                                  # attn_implementation=\"flash_attention_2\"\n",
    "                                                  token=token\n",
    "                                                 )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True, token=token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left' # to prevent errors with FA\n",
    "tokenizer.truncation_side = 'left'\n",
    "model = PeftModel.from_pretrained(base_model, \"checkpoint-750\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "820c18e6-52bf-41d1-b17d-424ec4e35183",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template = \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad026633-b2f1-4c29-ae34-cff750270839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('prompt_dataset_RLHF.json') as json_file:\n",
    "    prompt_dataset_RLHF = json.load(json_file)\n",
    "\n",
    "prompts = [sample['prompt'] for sample in prompt_dataset_RLHF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d206ecf-ae1f-4288-90cf-2b5a48d1ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-14 07:32:06 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80acaf45d3a4870acfafa43cfdd11da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 02-14 07:32:08 config.py:2386] Casting torch.float16 to torch.bfloat16.\n",
      "INFO 02-14 07:32:15 config.py:542] This model supports multiple tasks: {'classify', 'embed', 'generate', 'reward', 'score'}. Defaulting to 'generate'.\n",
      "INFO 02-14 07:32:15 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='musketshugging/finetuned-mistral-750', speculative_config=None, tokenizer='musketshugging/finetuned-mistral-750', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=musketshugging/finetuned-mistral-750, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f460a93ac248448d5c102a0c24330e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6335e275b3e847d2b516f2f6059f0379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1ac809056f419aa0b5ee8bab24e7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.51M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111cbbbafd6b4345b4947e09b9575a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3853ae5ac24f6a88216b45241a0fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-14 07:32:19 cuda.py:230] Using Flash Attention backend.\n",
      "INFO 02-14 07:32:20 model_runner.py:1110] Starting to load model musketshugging/finetuned-mistral-750...\n",
      "INFO 02-14 07:32:20 weight_utils.py:252] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5a0681fda54ac2bc3ab9654616ca53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b106a4687ee494ab0e5c3d221f18ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24190fd8d596418694866924ca505c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6bfbf852554e8f99f7522defde674a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a503528b274c4984901d0d24d9d486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-14 07:37:46 model_runner.py:1115] Loading model weights took 13.4967 GB\n",
      "INFO 02-14 07:37:47 worker.py:267] Memory profiling takes 0.87 seconds\n",
      "INFO 02-14 07:37:47 worker.py:267] the current vLLM instance can use total_gpu_memory (79.15GiB) x gpu_memory_utilization (0.80) = 63.32GiB\n",
      "INFO 02-14 07:37:47 worker.py:267] model weights take 13.50GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 0.31GiB; the rest of the memory reserved for KV Cache is 49.42GiB.\n",
      "INFO 02-14 07:37:47 executor_base.py:110] # CUDA blocks: 25302, # CPU blocks: 2048\n",
      "INFO 02-14 07:37:47 executor_base.py:115] Maximum concurrency for 2048 tokens per request: 197.67x\n",
      "INFO 02-14 07:37:53 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:18<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-14 07:38:12 model_runner.py:1562] Graph capturing finished in 18 secs, took 0.87 GiB\n",
      "INFO 02-14 07:38:12 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 25.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "# Path to your local model directory\n",
    "model_path = \"musketshugging/finetuned-mistral-750\"\n",
    "# model_path = \"facebook/opt-125m\"\n",
    "\n",
    "llm = LLM(model=model_path, dtype=torch.bfloat16, trust_remote_code=True, max_model_len=2048, gpu_memory_utilization = 0.8)\n",
    "\n",
    "# # Define sampling parameters (optional)\n",
    "sampling_params = SamplingParams(temperature=0.7, max_tokens=256, top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b7507f-e4e6-4cb4-bb4b-6347d54e61c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1000/1000 [02:33<00:00,  6.52it/s, est. speed input: 5607.86 toks/s, output: 1273.28 toks/s]\n",
      "Processed prompts: 100%|██████████| 1000/1000 [02:34<00:00,  6.46it/s, est. speed input: 5554.93 toks/s, output: 1270.67 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses saved to generated_responses.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import json\n",
    "\n",
    "def generate_responses(prompts, num_responses=2, sampling_params=None):\n",
    "    all_outputs = [] # List to store all outputs for all prompts\n",
    "    for _ in range(num_responses): # generate num_responses for all prompts\n",
    "\n",
    "        outputs = llm.generate(prompts, sampling_params)\n",
    "        all_outputs.append(outputs)\n",
    "    \n",
    "    responses = []\n",
    "    for i in range(len(prompts)): # iterate over all prompts\n",
    "        prompt_responses = [] # Store responses for the current prompt\n",
    "        for j in range(num_responses): # iterate over the num_responses\n",
    "            generated_text = all_outputs[j][i].outputs[0].text.strip()\n",
    "            prompt_responses.append(generated_text)\n",
    "        responses.append(prompt_responses)\n",
    "    return responses\n",
    "\n",
    "# Generate responses for ALL prompts at once\n",
    "all_responses = {}\n",
    "responses = generate_responses(prompts, num_responses=2, sampling_params=sampling_params) # Process first 5\n",
    "\n",
    "# Create the dictionary mapping prompts to responses\n",
    "for i, prompt in enumerate(prompts):\n",
    "    all_responses[prompt] = responses[i]\n",
    "\n",
    "# Save generated responses\n",
    "with open(\"generated_responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_responses, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Responses saved to generated_responses.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc7144a4-7458-4c9c-bd33-afaab209148d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a994a70e64aa4c22b05edd85ba574008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5c55d7499a4e98951c94d2950c6c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f094ef7483f44c6bbef7862a79b3255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant.\n",
      "<|im_start|>assistant\n",
      "You are in Seat 6 holding [8\n",
      "<|im_start|>assistant\n",
      "You are in Seat 6 holding [8\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "DEFAULT_SYSTEM_MESSAGE = \"You are a helpful AI assistant.\"\n",
    "\n",
    "def create_formatted_triplets(example, tokenizer, default_system_message=DEFAULT_SYSTEM_MESSAGE):\n",
    "    prompt = example[\"prompt\"]\n",
    "    chosen = example[\"chosen\"]\n",
    "    rejected = example[\"rejected\"]\n",
    "\n",
    "    prompt_messages = []\n",
    "    if not prompt.strip().startswith(\"<|system|>\"):\n",
    "        prompt_messages.append({\"role\": \"system\", \"content\": default_system_message})\n",
    "        prompt_messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    else:\n",
    "        parts = prompt.split(\"<|\")\n",
    "        for part in parts[1:]:\n",
    "            role, content = part.split(\"|>\", 1)\n",
    "            prompt_messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    chosen_messages = [{\"role\": \"assistant\", \"content\": chosen}]\n",
    "    rejected_messages = [{\"role\": \"assistant\", \"content\": rejected}]\n",
    "\n",
    "    return {\n",
    "        \"prompt\": tokenizer.apply_chat_template(prompt_messages, tokenize=False),\n",
    "        \"chosen\": tokenizer.apply_chat_template(chosen_messages, tokenize=False),\n",
    "        \"rejected\": tokenizer.apply_chat_template(rejected_messages, tokenize=False)\n",
    "    }\n",
    "\n",
    "# 1. Load data as Dataset:\n",
    "dataset = load_dataset(\"json\", data_files=\"preference_data.json\", split=\"train\") # Load with split\n",
    "\n",
    "# 3. Apply mapping:\n",
    "dataset = dataset.map(\n",
    "    create_formatted_triplets,\n",
    "    remove_columns=dataset.column_names,  # Or dataset.column_names[\"train\"] if loaded with split\n",
    "    fn_kwargs={\"tokenizer\": tokenizer}\n",
    ")\n",
    "\n",
    "# 4. Split and save:\n",
    "if \"dataset_dict\" not in locals(): # Check if we loaded a single dataset\n",
    "    dataset = dataset.train_test_split(test_size=200/1000)  # Corrected split size (20%)\n",
    "    dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
    "    dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")\n",
    "else: # If we loaded the dataset_dict\n",
    "    dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
    "    dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")\n",
    "\n",
    "\n",
    "# 5. Print examples:\n",
    "if len(dataset[\"train\"]) > 0: # Check if the dataset is not empty before accessing the first element.\n",
    "  print(dataset[\"train\"][0][\"prompt\"][:50])\n",
    "  print(dataset[\"train\"][0][\"chosen\"][:50])\n",
    "  print(dataset[\"train\"][0][\"rejected\"][:50])\n",
    "else:\n",
    "  print(\"Training dataset is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "541563ad-9456-427b-8589-f23a2dbc770a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecc5752079e4d97ae40100d5f13ef0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa7ee7f2e8748e4b4374ffc2cac4913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    " \n",
    "# Load jsonl data from disk\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81bd51b1-af08-4654-a56b-a05fa616d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM\n",
    "\n",
    "# BitsAndBytesConfig int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(  # PEFT configuration for efficient fine-tuning\n",
    "    lora_alpha=128, lora_dropout=0.05, r=256, bias=\"none\", target_modules=\"all-linear\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "tokenizer.padding_side = 'left' # to prevent errors with FA\n",
    "tokenizer.truncation_side = 'left' # to prevent cutting off last generation\n",
    "\n",
    "\n",
    "# 2. Set up Training Parameters\n",
    "prompt_length = 1024  # Adjust based on your data.  Experiment!\n",
    "max_seq_length = 1512  # Adjust based on your data. Experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5d6da-452e-4e13-9706-424b8e217ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "/tmp/ipykernel_1580/3510558958.py:32: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `DPOTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = DPOTrainer(\n",
      "/venv/main/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/venv/main/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/67 02:43 < 16:59, 0.05 it/s, Epoch 0.15/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.684779</td>\n",
       "      <td>-0.577823</td>\n",
       "      <td>-0.809653</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.231830</td>\n",
       "      <td>-294.372131</td>\n",
       "      <td>-297.073120</td>\n",
       "      <td>-3.748905</td>\n",
       "      <td>-3.744868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/50 00:55 < 00:20, 0.65 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=128, lora_dropout=0.05, r=256, bias=\"none\", target_modules=\"all-linear\", task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# Use DPOConfig\n",
    "dpo_config = DPOConfig(\n",
    "    output_dir=\"dolphin-dpo\",\n",
    "    num_train_epochs=1,\n",
    "    # max_steps=2000,  # Set the desired number of training steps\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    learning_rate=5e-5,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=5,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    beta=0.1,  # DPO Beta parameter\n",
    "    loss_type=\"sigmoid\"  # DPO Loss type\n",
    ")\n",
    "# 3. Train the model\n",
    "trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None,  # Set to None since we're using PEFT\n",
    "    peft_config=peft_config,\n",
    "    args=dpo_config,  # Use DPOConfig\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e1e63db-db25-4922-82b2-f3ad6742afbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9087b5191641a399a00feae1bc64c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ff9123e81c4323afc887f68900b371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1c6d29311a442aa55438fe77cb759a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0ee7283578441c81a60a15126d43c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211e6edcc0e04095ab61da9517a8c4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ede571b816d42cf8c836fe8d9fe421a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c597afcd3de4c9b86736ca23a84ee01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/musketshugging/finetuned-mistral-750/commit/be709bd3703411560492df5a5cacf05fafce40f3', commit_message='Upload tokenizer', commit_description='', oid='be709bd3703411560492df5a5cacf05fafce40f3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/musketshugging/finetuned-mistral-750', endpoint='https://huggingface.co', repo_type='model', repo_id='musketshugging/finetuned-mistral-750'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from peft import PeftModel\n",
    "\n",
    "# 1. Define your model and PEFT adapter paths\n",
    "base_model_name = \"mistralai/Mistral-7B-v0.1\"  # Or your preferred base model\n",
    "peft_model_path = \"mistral-journal-finetune/checkpoint-750\"  # Path to your PEFT adapter\n",
    "merged_model_name = \"musketshugging/finetuned-mistral-750\" # Name for the merged model on Hugging Face Hub\n",
    "\n",
    "# 2. Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 3. Load the base model (WITHOUT quantization)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,  # Important for mixed precision (if your GPU supports it)\n",
    "    trust_remote_code=True # Add this if you are using llama\n",
    ")\n",
    "\n",
    "# 4. Load the PEFT adapter\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    peft_model_path,\n",
    "    torch_dtype=torch.float16, # Match the base model's dtype\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# 5. Merge the adapter and unload the PEFT model\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# 6. Save the merged model and tokenizer\n",
    "model.save_pretrained(merged_model_name)\n",
    "tokenizer.save_pretrained(merged_model_name)\n",
    "\n",
    "# 7. Push the merged model to the Hugging Face Hub (optional but recommended)\n",
    "model.push_to_hub(merged_model_name, token='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') # Ensure you have your Hugging Face token set up\n",
    "tokenizer.push_to_hub(merged_model_name, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3867b37c-fb15-4c30-a9d2-08f7564c545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bc7798c-e7ca-4db4-9b1d-f6086dffa2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm is a vllm.LLM object\n",
    "import gc\n",
    "import torch\n",
    "from vllm.distributed.parallel_state import destroy_model_parallel\n",
    "import os\n",
    "\n",
    "#avoid huggingface/tokenizers process dead lock\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "destroy_model_parallel()\n",
    "#del a vllm.executor.ray_gpu_executor.RayGPUExecutor object\n",
    "del llm.llm_engine.model_executor\n",
    "del llm\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "import ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2f698-3099-469d-94dd-e5830a2724b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
