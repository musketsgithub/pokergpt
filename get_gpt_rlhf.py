import json
import asyncio
import aiohttp
import ssl
import certifi
from tqdm import tqdm
from datasets import Dataset, DatasetDict

with open('generated_responses.json','r') as json_file:
    all_responses = json.load(json_file)

# OpenAI API settings (REDACTED KEY)
MODEL = "gpt-4o-mini"  # Or gpt-3.5-turbo
OPENAI_SECRET_KEY = "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"  # Replace with your actual key
API_URL = "https://api.openai.com/v1/chat/completions"

# Limit concurrent requests
CONCURRENT_REQUESTS = 2

async def call_chatgpt_async(session, prompt):
    """Send a single prompt to OpenAI and return the response."""
    messages = [{"role": "user", "content": prompt['opinion_request']}]

    payload = {
        'model': MODEL,
        'messages': messages
    }

    try:
        async with session.post(
                url=API_URL,
                headers={"Content-Type": "application/json", "Authorization": f"Bearer {OPENAI_SECRET_KEY}"},
                json=payload,
                ssl=ssl.create_default_context(cafile=certifi.where())
        ) as response:
            result = await response.json()

            if "error" in result:
                print(f"❌ OpenAI request failed: {result['error']}")
                return None

            content = result['choices'][0]['message']['content']

            return {'prompt': prompt['prompt'], 'response1': prompt['response1'], 'response2':prompt['response2'],'opinion':content}

    except Exception as e:
        print(f"❌ Request failed: {e}")
        return None  # Return None for exceptions


async def gpt_opinion_request(prompts):
    """Process all prompts with limited concurrency and track progress."""
    semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS)
    results = None

    async def limited_call(prompt, progress_bar, counter):
        async with semaphore:
            result = await call_chatgpt_async(session, prompt)
            progress_bar.update(1)

            if counter % 100 == 0 and counter!=0:
                print(f"Processed {counter} prompts. Waiting for 30 seconds...")
                await asyncio.sleep(30)  # Wait for 30 seconds after every 500 requests

            return result

    async with aiohttp.ClientSession() as session:
        with tqdm(total=len(prompts), desc="Processing Prompts") as progress_bar:
            tasks = []
            counter = 0
            for prompt in prompts:
                tasks.append(limited_call(prompt, progress_bar, counter))
                counter += 1

            results = await asyncio.gather(*tasks)

    return results

gpt_opinion_requests = [{'opinion_request': f"You will be provided with a prompt and two responses generated by another AI. Choose the response that is better overall, considering factors such as adherence to prompt, accuracy, quality, depth of analysis, etc. Essentially choose which is a better and more accurate poker analysis and action based on the prompt. Respond with either “1” or “2” only. Respond with NOTHING else in your answer except “1” or “2”.\n\nPrompt:\n\"\n{prompt}\n\"\n\nResponse 1:\n\"\n{all_responses[prompt][0]}\n\"\n\nResponse 2:\n\"\n{all_responses[prompt][1]}\n\"", "prompt": prompt, "response1": all_responses[prompt][0], "response2": all_responses[prompt][1]} for prompt in all_responses]

opinions = asyncio.run(gpt_opinion_request(gpt_opinion_requests))

preference_data = []

for opinion in opinions:
    if opinion['opinion']=='1':
        preference_data.append({
            "prompt": opinion['prompt'],
            "chosen": opinion['response1'],
            "rejected": opinion['response2']
        })
    elif opinion['opinion']=='2':
        preference_data.append({
            "prompt": opinion['prompt'],
            "chosen": opinion['response2'],
            "rejected": opinion['response1']
        })
    else:
        print("ChatGPT didn't choose 1 or 2.")

with open('preference_data.json','w') as json_file:
    json.dump(preference_data, json_file)